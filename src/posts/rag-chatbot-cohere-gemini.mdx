---
title: "Building a RAG-Based Multi-Domain AI Chatbot using Cohere, ChromaDB & Google Gemini"
date: "June 21, 2025"
excerpt: "Explore how I built a powerful Retrieval-Augmented Generation chatbot using Python, ChromaDB, Cohere Embeddings, Google Gemini LLM, and Redis to support domain-specific knowledge querying with performance optimization."
coverImage: "/images/rag-chatbot-cover.jpg"
tags: ["Chatbot", "Python", "Cohere", "Gemini LLM", "ChromaDB", "FastAPI", "React", "RAG"]
author: "Himadri Karan"
---

# RAG-Based Multi-Domain AI Chatbot with Cohere + Gemini

This project demonstrates how to build a scalable **Retrieval-Augmented Generation (RAG)** chatbot that can answer queries across multiple knowledge domains using vector embeddings and large language models.

---

## ðŸš€ What Youâ€™ll Learn

- How to use **Cohere** for embedding documents and queries  
- Setting up **ChromaDB** for similarity search  
- Integrating **Google Gemini LLM** for natural language responses  
- Using **FastAPI + React** for a clean full-stack experience  
- Optimizing with **Redis** and credit tracking  
- Supporting multiple knowledge domains (e.g., Education, Legal, Healthcare)

---

## ðŸ§± Tech Stack Overview

- **Backend:** Python, FastAPI, Cohere, ChromaDB, Google Gemini API, Upstash Redis  
- **Frontend:** React.js, Tailwind CSS  
- **Storage:** Local file system + ChromaDB vector store  
- **Auth & Usage Control:** Redis-based credit system

---

## ðŸ§  How It Works

1. **Ingestion Phase**
   - Documents are chunked and embedded using Cohere.  
   - Embeddings are stored in **ChromaDB** under domain-specific collections.

2. **Query Phase**
   - User inputs a query through the React interface.  
   - The query is embedded at runtime and matched against the selected domain's ChromaDB collection.  
   - Retrieved contexts are combined into a prompt and passed to **Google Gemini** for answer generation.

3. **Redis for Credit Control**
   - Tracks per-user API usage with TTL (Time-to-Live) logic.  
   - Helps manage rate limits and cost control.

---

## ðŸ“¦ Sample Folder Structure
```
Backend_Server/
â”‚
â”œâ”€â”€ app/                  # Core logic
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ retriver.py
â”‚   â”œâ”€â”€ embedder.py
â”‚   â”œâ”€â”€ llm.py
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ credit_tracker.py
â”‚
â”œâ”€â”€ chroma_store/         # Chroma vector store
â”œâ”€â”€ sampleData/           # Source docs in JSON
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ .gitignore
```
---

## ðŸ› ï¸ Redis Credit Tracking Example

```python
def track_credits(user_id: str) -> bool:
    key = f"user:{user_id}:credits"
    current = redis.get(key)

    if current is None:
        redis.set(key, DEFAULT_CREDITS - 1, ex=TTL_SECONDS)
        return True
    if int(current) <= 0:
        return False

    redis.decr(key)
    return True
```
---
## ðŸ’» Frontend with React + Tailwind

- Clean interface for domain selection
- Query input box with real-time results
- Context citations for each answer
- Responsive layout with Tailwind CSS

---

### âœ… Prerequisites

- Python 3.9+
- Node.js 18+
- Redis (Upstash or local)
- ChromeDB (local file-based)
- API keys: `GEMINI_API_KEY`, `COHERE_API_KEY`, `REDIS_URL`, `REDIS_TOKEN`

---

### ðŸ”§ Installation

```bash
# Clone the repository
git clone https://github.com/your-username/rag-chatbot.git
cd rag-chatbot/Backend_Server

# Create virtual environment
python -m venv venv
venv\Scripts\activate     # on Windows

# Install dependencies
pip install -r requirements.txt
```
---

## âš™ï¸ Configuration

Create a `.env` file in the root:
```js
COHERE_API_KEY=your_key
GEMINI_API_KEY=your_key
REDIS_URL=https://...
REDIS_TOKEN=your_token
```
---

## ðŸ’¡ Usage Guide

1. Start Backend Server
```bash
cd app
uvicorn main:app --reload
```
2. Start Frontend Server
```bash
cd Chat_UI
npm install
npm run dev
```
3. Interact via Browser

- Open `http://localhost:5173`
- Ask queries related to healthcare, education, law, etc.
---

## ðŸ”’ Security Features
- âœ… Environment variables for all sensitive keys
- âœ… Credit-based usage control via Redis
- âœ… Token-level rate limiting (Upstash)
- â›” No hardcoded credentials in production
---

## ðŸŽ¯ Performance Optimization
- âš¡ Efficient semantic search using ChromaDB
- ðŸ” Batched embedding with Cohere
- ðŸ”„ Redis caching to reduce API overuse
- ðŸ“¦ Modular design to plug-and-play new domains
---

## ðŸ”„ Future Enhancements
- ðŸ§¬ Add support for OpenAI/SentenceTransformers
- ðŸ—ƒï¸ Optional Pinecone/Weaviate for scalable vector storage
- ðŸ§‘â€ðŸ’» User authentication and role-based access
- ðŸ§  Feedback learning loop for continuous improvement
- ðŸ“Š Admin dashboard for monitoring & analytics
- ðŸ“¦ Docker + CI/CD for deployment pipeline
---

## ðŸ™ Acknowledgments
- Google Gemini API
- Cohere
- ChromaDB
- FastAPI
- Upstash Redis
- Open-source community & contributors

---

## ðŸŽ‰ Conclusion

This RAG-based chatbot demonstrates the power of combining modern LLMs with vector databases for domain-specific knowledge retrieval. The integration of Cohere embeddings with Google Gemini provides accurate, contextual responses while maintaining scalability through Redis caching and ChromaDB's efficient vector operations.

**Key Takeaways:**
- âœ… RAG significantly improves response accuracy for specialized domains
- âœ… Vector embeddings enable semantic search across large knowledge bases  
- âœ… Proper caching and rate limiting are crucial for production deployment
- âœ… Modular architecture allows easy expansion to new domains

Feel free to explore the code, contribute improvements, or adapt it for your own use cases!

<SocialLinks 
  linkedinUrl="https://linkedin.com/in/himadrikaran"
  githubUrl="https://github.com/karanhimadri/RAG-Based-ChatBot.git"
  youtubeUrl=""
/>


